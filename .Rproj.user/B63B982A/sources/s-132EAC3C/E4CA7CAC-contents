---
title: "mlm_final_kavya"
author: "Kavya Mudiam"
date: "6/7/2021"
output: html_document
---

```{r}
library(rio)
library(dplyr)
library(here)
library(ggplot2)
library(tidyverse)
library(lme4)
```

# Loading and formatting data
```{r}
data <- import(here("data", "data.csv"))
data_filt <- data %>% 
  filter(scale_name %in% c("CVS", "RMPI", "ULS-8")) %>% 
  mutate(#survey_name = as.factor(survey_name),
         scale_name = as.factor(scale_name),
         scored_scale = as.factor(scored_scale),
         SID = as.factor(SID)
         )
data_filt <- data_filt %>% 
  filter(!scored_scale %in% c("hs gpa", "senior gpa", "year graduated hs", "age of first drink", "father edu", "first gen yn", "housing", "hs type", "money", "money 1", "mother edu", "pathway"))

data_filt <- data_filt %>% 
  mutate(time = parse_number(survey_name),
         time = as.factor(time)) %>% 
  select(-method)


data_filt$score[data_filt$n_items == 0] <- NA
data_filt$scale_name <- as.character(data_filt$scale_name)
data_filt$scored_scale <- as.character(data_filt$scored_scale)
data_filt <- data_filt %>%
     mutate(scale_name = case_when(scale_name =="CVS"~ scored_scale,
                            TRUE ~ scale_name))


### Going to remove the ULS that was completed at T2 Follow Up and only keep the T2 Check In because that came first and because they are both being coded as timepoint 2. 
data_filt$survey_name[data_filt$survey_name == "FP MRI T2 Follow Up" & data_filt$scale_name == "ULS-8"] <- "drop"
data_filt$survey_name[data_filt$survey_name == "FPS GPS MINUS T2 Follow Up" & data_filt$scale_name == "ULS-8"] <- "drop"
data_filt$survey_name[data_filt$survey_name == "FPS GPS PLUS T2 Follow Up" & data_filt$scale_name == "ULS-8"] <- "drop"

data_filt <- data_filt %>% 
  filter(survey_name != "drop") # Got rid of the rows that had ULS at follow up 

# Turn data wide/long?
##trying this without the weird scale_time thing 
data_l <- data_filt %>% 
  pivot_wider(id_cols = c(SID, time),
              names_from = scale_name,
              values_from = score) %>% 
  arrange(SID)


# data_l$scale_time <- as.factor(data_l$scale_time)
# data_l %>% 
#   group_by(SID, scale_time) %>% 
#   count() %>% 
#   filter(n>1)
# 
# data_l <- data_l %>% 
#   pivot_wider(id_cols = c(SID, time, scale_time),
#               names_from = scale_name,
#               values_from = score) %>% 
#   arrange(SID)

# ## Combining timepoints & scale name
# data_l$scale_time <- paste(data_l$scale_name,"_",data_l$time) 
# data_l$scale_time <- gsub('\\s+', '', data_l$scale_time) #removing spaces

# Create a column for just baseline ULS
data_l$NA_col <- NA 
data_l$NA_col <- as.numeric(data_l$NA_col)

data_l <- data_l %>%
     mutate(ULS_BL = case_when(time == "2" ~ `ULS-8`,
                            TRUE ~ `NA_col`))

data_l <- data_l %>% 
  group_by(SID) %>% 
  fill(ULS_BL, .direction = "downup")

data_l <- data_l %>% 
  select(-NA_col) 

## filling other demographic stuff
data_l <- data_l %>% 
  group_by(SID) %>% 
  fill(ULS_BL, .direction = "downup")

###finalized data set
data_l <- data_l %>% 
  group_by(SID) %>% 
  fill(gender, .direction = "downup")
data_l <- data_l %>% 
  group_by(SID) %>% 
  fill(hispanic, .direction = "downup")
data_l <- data_l %>% 
  group_by(SID) %>% 
  fill(sex, .direction = "downup")

## removing some variables
data_l <- data_l %>% 
  select(- `ethnicity text`)


## time as numeric
data_l %>% 
  mutate(time = as.numeric(time))

# names(data_l)
# age
# ethnicity text
# hs gpa
# senior gpa
# year graduated hs
# age of first drink
# father edu
# first gen yn
# gender
# hispanic
# housing
# hs type
# money
# money 1
# mother edu
# pathway
# sex
``` 

# Cleaning Data, identifying missingness, etc
```{r}
#Rutgers Marijuana Problematic Inventory
 data_filt %>%
   filter(scale_name == "RMPI") %>%
   select(SID, time, survey_name, n_items) %>%
   group_by(n_items) %>%
   count() #RMPI - 852 missing, 325 completed

data_filt %>% 
  filter(scale_name == "RMPI") %>% 
  select(SID, time, survey_name, n_items) %>% 
  group_by(n_items, time) %>% 
  count()

data_filt %>% 
  filter(scale_name == "RMPI") %>% 
  ggplot(aes(x = score)) +
  geom_histogram()



#Loneliness Scale
##n_items completed
data_filt %>% 
  filter(scale_name == "ULS-8") %>% 
  select(SID, time, survey_name, n_items) %>% 
  group_by(n_items) %>% 
  count()#ULS-8 not collected at T1. 1161 completed, 12 not completed
##n_items completed by timepoint
data_filt %>% 
  filter(scale_name == "ULS-8") %>% 
  select(SID, time, survey_name, n_items) %>% 
  group_by(n_items, time) %>% 
  count() 

##change the dataset so that the score for 0 items filled = NA
data_filt$score[data_filt$n_items == 0] <- NA
##look at missing data
naniar::vis_miss(data_filt) #3% missing data in total, 28% scores missing
naniar::vis_miss(data_l) #73% missing data for RMPI .... that's a lot of missing data. Might be most appropriate to impute data.

##Number of completers at each timepoint 
data_filt %>% 
  filter(scale_name == "ULS-8") %>% 
  select(SID, time, survey_name, n_items) %>% 
  group_by(n_items, time) %>% 
  count() 


##Less missing data if there are less timepoints?
data_short <- data_l %>% 
  filter(time == 1| time == 5)
naniar::vis_miss(data_short)

```
```{r}
library(mice)
# imp <- mice(data_l, m = 5)
# imp <- mice(data_l, me = c("polyreg", "polyreg", "pmm", "pmm","pmm","pmm","pmm","pmm"))

## Unable to impute the data. Receiving error: Error in terms.formula(tmp, simplify = TRUE) : invalid model formula in ExtractVars
```

# Exploratory and descriptive analyses: 3 points

>One of the most important components of analysis work generally is knowing your data well. The exploratory and descriptive analyses will inform you on whether you data meet your model assumptions and, if not, what data transformations or amendments to your model should be made. Note that it is acceptable to identify areas where the data may not meet the model assumptions, note them, and move on. In other words, you do not have to address everything you find, but they should be noted in the limitations section of your writeup.

```{r}

```



# Model assumptions
>check the spread of responses

##RMPI
```{r}
#histogram/distribution faceted by timepoint
data_filt %>% 
  filter(scale_name == "RMPI") %>% 
  ggplot(aes(x = score)) +
  geom_histogram(fill = "#61adff",
                 color = "white") +
  facet_wrap(~time) #A lot of 0s - similar patterns at all of the timepoints. This is the outcome variable, so not going to transform it. Perhaps a zero-inflated model would be more appropriate. 

##average RMPIs at each timepoint
data_filt %>% 
  filter(scale_name == "RMPI")  %>% 
  group_by(time) %>% 
  summarise(mean(score, na.rm = T)) 

##PLOT: average RMPIs at each timepoint
data_filt %>% 
  filter(scale_name == "RMPI")  %>% 
  group_by(time) %>% 
  summarise(rmpi_mean = mean(score, na.rm = T)) %>% 
  ggplot(aes(x = time, y = rmpi_mean)) +
  geom_col(aes(fill = time))   

```

##ULS-8
```{r}
##histogram/distribution faceted by timepoint and all timepoints
data_filt %>% 
  filter(scale_name == "ULS-8") %>% 
  ggplot(aes(x = score)) +
  geom_histogram() +
  facet_wrap(~time) #mostly normal distribution at all timepoints
data_filt %>% 
  filter(scale_name == "ULS-8") %>% 
  ggplot(aes(x = score)) +
  geom_histogram() #mostly normal distribution

##average ULS-8 at each timepoint
data_filt %>% 
  filter(scale_name == "ULS-8")  %>% 
  group_by(time) %>% 
  summarise(mean(score, na.rm = T)) 
##PLOT: average ULS8 at each timepoint
data_filt %>% 
  filter(scale_name == "ULS-8")  %>% 
  group_by(time) %>% 
  summarise(uls_mean = mean(score, na.rm = T)) %>% 
  ggplot(aes(x = time, y = uls_mean)) +
  geom_col(aes(fill = time))   
```


#Analysis
>Depending on your specific situation, you may engage in a model building process (starting with a baseline model and adding predictors) or you may have a specific model in mind a priori that you can directly estimate. In either case, the model should map directly to the research question and be properly specified. There are often judgments that must be made in your analysis and your decisions should be clear from the evidence. You can defend these judgments in your writeup, but failure to properly evaluate important decision points (e.g., whether a variable should randomly vary or not) without theoretical justification in the writeup will result in a loss of points.

*Research Qs:*
>>*How does severity of problematic use at baseline predict the severity of problematic substance use at later timepoints and how does this vary between undergraduate students?*

```{r}
m0 <- lmer(RMPI ~ time + (1|SID),
           data = data_l)
arm::display(m0)
```

>>*How does severity of problematic substance use change over time, and vary within and between undergraduate students?*
## Unable to test random effects of slope bc the number of observations is so low

```{r}
# m1 <- lmer(RMPI ~ time + (time|SID),
#            data = data_l)
# 
# arm::display(m1)
```

>>*How does loneliness at an early timepoint predict problematic substance use throughout college and between students?*

```{r}
m1 <- lmer(RMPI ~ ULS_BL + time + (1|SID),
           data = data_l)

arm::display(m1)
```


#Plots
>You are required to create one plot from your model that communicates the coefficients, model predictions, or other features. You are welcome to include more than one, but at least one plot should be created.
